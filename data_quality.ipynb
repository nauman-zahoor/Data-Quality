{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically assess quality of a dataset before doing any manual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext#0.8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#pd.set_option('display.max_rows', 120)\n",
    "#pd.set_option('display.max_columns', 30)\n",
    "#pd.set_option('display.width', 1000) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stop_words = list(set(list(STOP_WORDS) + list(ENGLISH_STOP_WORDS)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "\n",
    "import string\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_model(df):\n",
    "    \n",
    "\n",
    "\n",
    "    #setting 'id' unique value for each row\n",
    "    ind=[]\n",
    "    for i in range(len(df)):\n",
    "        ind.append(i)\n",
    "    df['ind']=ind\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Train and Test set (70%-30% for each category class)\n",
    "    groups=list(set(df['out_class'].tolist()))\n",
    "    df_train1=pd.DataFrame(columns=df.columns.tolist())\n",
    "    for g in groups:\n",
    "        df1=df[df['out_class']==g]\n",
    "        df1=df1[:int(len(df1)*.70)]\n",
    "        df_train1=pd.concat([df_train1,df1])\n",
    "\n",
    "    df_test1=df[~(df['ind'].isin(df_train1['ind']))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    f = open('all_tickets_train.txt','w')\n",
    "\n",
    "    train_size=df_train1.shape[0]\n",
    "    for i in range(df_train1.shape[0]):\n",
    "        label=str(df_train1['out_class'].iloc[i])\n",
    "        label=label.replace(\" \", \"-\")\n",
    "        label=label.lower()\n",
    "\n",
    "        body=str(df_train1['merged'].iloc[i])\n",
    "        body=body.translate(str.maketrans('','',string.punctuation))\n",
    "        body=body.replace('\\n',' ')\n",
    "        body=body.lower()\n",
    "        f.write('__label__'+label+' '+body+'\\n')\n",
    "\n",
    "    f.close()\n",
    "    print('\\nWritten')\n",
    "    classifier = fasttext.supervised('all_tickets_train.txt','model_all_text',lr=0.025,epoch=25,word_ngrams=2,bucket=200000,dim=300,loss='softmax')\n",
    "    print('Classifier Trained')\n",
    "    # classifier.save_model(\"model_all_tickets.bin\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    sent=[]\n",
    "    labels=[]\n",
    "\n",
    "    t_size=df_test1.shape[0]\n",
    "    for i in range(df_test1.shape[0]):\n",
    "        label=str(df_test1['out_class'].iloc[i])\n",
    "        label=label.replace(\" \", \"-\")\n",
    "        label=label.lower()\n",
    "        labels.append(label)\n",
    "\n",
    "        body=str(df_test1['merged'].iloc[i])\n",
    "        body=body.translate(str.maketrans('','',string.punctuation))\n",
    "        body=body.replace('\\n',' ')\n",
    "        body=body.lower()\n",
    "        sent.append(body)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_result=pd.DataFrame(columns=['real','pred'])\n",
    "    pred=[]\n",
    "    for s in sent:\n",
    "        prediction=classifier.predict([s])[0][0]\n",
    "        pred.append(prediction)\n",
    "        #print(len(pred))\n",
    "\n",
    "\n",
    "    df_result['pred']=pred\n",
    "    df_result['real']=labels\n",
    "\n",
    "\n",
    "    \n",
    "    #print('Accuracy: ',accuracy_score(pred,labels))\n",
    "    #print('f1_score: ',f1_score(pred,labels, average='weighted'))\n",
    "\n",
    "    return accuracy_score(pred,labels),f1_score(pred,labels, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading Other Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./../input/all_data.csv')\n",
    "\n",
    "\n",
    "mapping = {\n",
    "    \"input_colls\" : {\n",
    "        \"coll1\" :\"title\", # \"name of column 1 in csv\"\n",
    "        \"coll2\": \"body\"},  # \"name of column 2 in csv\"\n",
    "    \"output_class\" : {\n",
    "        \"coll1\":\"category\"},  # \"name of out class column 1 in csv\"\n",
    "    \"important_out_class\" : \"\" # list of classes to classify. If empty, consider all classes in csv\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_text = \"\"\n",
    "out_text = out_text + '\\n'+ \"Data Stats:\"\n",
    "print('Data Stats:')\n",
    "\n",
    "\n",
    "\n",
    "txt =  'Total Dataset Size = ' + str(len(data))\n",
    "print(txt)\n",
    "out_text = out_text + '\\n'+ txt\n",
    "\n",
    "\n",
    "\n",
    "inp_cols = list (mapping['input_colls'].values()) \n",
    "out_cols = list (mapping['output_class'].values())\n",
    "inp = data.loc[:,inp_cols]\n",
    "out = data.loc[:,out_cols]\n",
    "out[out_cols] = out[out_cols].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for c in inp_cols:\n",
    "    txt = 'Unique values in \"' + str(c) + '\"  = ' + str(len(inp.loc[:,c].unique())) + '/' + str(len(data))\n",
    "    print(txt)\n",
    "    out_text = out_text +  '\\n' + txt\n",
    "\n",
    "    \n",
    "txt =  'Unique values in \"' + str(out_cols[0]) + '\"  = ' + str(len(out.loc[:,out_cols[0]].unique()) )   \n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "\n",
    "inp = inp.fillna('')\n",
    "out = out.fillna('')\n",
    "\n",
    "\n",
    "# Merging input\n",
    "merged_inp = inp.apply(lambda x: x.str.cat(sep=','), axis=1)\n",
    "merged_inp = pd.DataFrame(merged_inp)\n",
    "merged_inp.columns=['merged']\n",
    "out.columns = ['out_class']\n",
    "data_all = pd.concat([merged_inp,out],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "txt = 'Unique values in  \"Merged input\" = ' + str(len(data_all.merged.unique()) ) + '/' +  str(len(data))\n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "\n",
    "# nan\n",
    "txt = 'Persentage of nans in Merged input  = ' + str(len(merged_inp[merged_inp.merged==','])*100/len(merged_inp)) + '%'\n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "txt = 'Persentage of nans in output = ' + str(len(out[out.out_class==''])*100/len(out)) + '%'\n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "\n",
    "######################### Red Rules\n",
    "out_text = out_text + '\\n\\n\\n'+ \"Red Rules:\"\n",
    "print('\\n\\nRed Rules:')\n",
    "\n",
    "\n",
    "\n",
    "persentage_nans = len(data_all[data_all.merged==','][data_all.out_class != ''])*100/len(data_all)\n",
    "txt = 'Persentage of input NAN with valid Output Class Assigned = ' + str(persentage_nans) + '%'\n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "persentage_nans = len(data_all[data_all.out_class==''][data_all.merged != ','])*100/len(data_all)\n",
    "txt = 'Persentage Output NANs with Valid input text = ' + str(persentage_nans) + '%'\n",
    "\n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# No of output clssses with data distribution\n",
    "\n",
    "df_t = data_all.out_class.value_counts()\n",
    "df_t2 = pd.DataFrame()\n",
    "df_t2.loc[:,'vals'] = df_t.index\n",
    "df_t2.loc[:,'counts'] = df_t.tolist()\n",
    "df_t2.loc[:,'counts'] = df_t2.loc[:,'counts']*100/max(df_t2.loc[:,'counts'])\n",
    "# Output Class Data Distribution\n",
    "df_t2.index = df_t2.vals\n",
    "\n",
    "\n",
    "#Red Rules:\n",
    "#1. Minimum number of records required for each assignment group\n",
    "#2. Same short+long description, going to different assignment groups\n",
    "\n",
    "#Yellow Rules:\n",
    "#Based on distribution point out classes for user to review the classes with comparivtely less data (print class names and percentage of records)\n",
    "\n",
    "#Minimum number of records required for each assignment group = 2% of highest class count\n",
    "#Recommended number of records required for each assignment group = 35% of highest class count\n",
    "\n",
    "\n",
    "\n",
    "min_vals_per_class = 3\n",
    "recommended_vals_per_class = 15\n",
    "\n",
    "x = len(df_t2[df_t2.counts<min_vals_per_class])\n",
    "\n",
    "txt = 'Output Classes not satisfying \"Minimum Class Examples\" requirement of having  less than ' + str(min_vals_per_class)  + '% maximum class example count  = '+str(x)+'/'+str(len(data_all.loc[:,'out_class'].unique()))\n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Plot\n",
    "\n",
    "df_t3 = df_t2.copy()\n",
    "df_t3.loc[df_t2['counts'].between(min_vals_per_class, recommended_vals_per_class+1),'colour'] = 'y'\n",
    "df_t3.loc[df_t2['counts']>recommended_vals_per_class,'colour'] = 'g'\n",
    "df_t3.loc[df_t2['counts']<min_vals_per_class,'colour'] = 'r'\n",
    "\n",
    "pie = df_t2.plot.bar(figsize=(15,10), color=[df_t3.colour.tolist()],title = 'Out Class Data Distribution. (Green = Good, Yellow = Acceptable, Red = Unacceptable)',fontsize = 8)\n",
    "\n",
    "plt.savefig('pie')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cleaning\n",
    "import re\n",
    "def clean_sent(sent):\n",
    "    sent = sent.lower()\n",
    "    special_chars2 = ['\\n','\\t','\\\\']\n",
    "    for i in special_chars2:\n",
    "        sent = sent.replace(i,' ')\n",
    "    special_chars = '~!@#$%^&*()_+{}[]:;\"<>?,./\\|`-='\n",
    "    for i in special_chars:\n",
    "        sent = sent.replace(i,' ')\n",
    "    special_chars3 = \"'\"\n",
    "    for i in special_chars3:\n",
    "        sent = sent.replace(i,' ')\n",
    "    sent = re.sub(' +', ' ',sent)\n",
    "    return sent\n",
    "\n",
    "\n",
    "data_all['merged'] = data_all['merged'].apply(clean_sent)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mis_classified_instances = data_all.groupby('merged').filter(lambda x : (len(x['merged'])==x['out_class'].nunique())&(len(x['merged'])>1))#.sort_values(by = 'merged')\n",
    "\n",
    "txt = 'Same input going to different Output classes: ' + str(len(mis_classified_instances))\n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "\n",
    "\n",
    "############################# Yellow Rules\n",
    "out_text = out_text + '\\n\\n\\n'+ \"Yellow Rules:\"\n",
    "print('\\n\\n\\nYellow Rules:')\n",
    "x = len(df_t2[df_t2.counts<recommended_vals_per_class])\n",
    "txt = 'Output Classes not satisfying \"Recommended Class Examples\" requirement of having  less than ' + str(recommended_vals_per_class)  + '% maximum class example count  = '+str(x)+'/'+str(len(data_all.loc[:,'out_class'].unique()))\n",
    "print(txt)\n",
    "out_text = out_text + '\\n' + txt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Append-adds at last \n",
    "#file1 = open(\"Results.txt\",\"w\")\n",
    "#file1.write(out_text) \n",
    "#file1.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Problematic Data and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Written\n",
      "Classifier Trained\n",
      "Accuraccy with NANs removed :  0.23283858998144713 \n",
      "F1 score with NANs removed :  0.3178429638769952\n",
      "\n",
      "Written\n",
      "Classifier Trained\n",
      "Accuraccy with no NANs and no Red Rules violating Classes :  0.261139896373057 \n",
      "F1 score with no NANs and no Red Rules violating Classes :  0.34808643117898075\n",
      "\n",
      "Written\n",
      "Classifier Trained\n",
      "Accuraccy with no NANs and no Red and Yellow Rules violating Classes :  0.3540701522170748 \n",
      "F1 score with no NANs and no Red and Yellow Rules violating Classes :  0.45570917828293933\n"
     ]
    }
   ],
   "source": [
    "# removing nans from merged data\n",
    "data_no_nans = data_all[data_all.merged != ','].copy()\n",
    "data_no_nans = data_no_nans[data_no_nans.out_class != ''].copy()\n",
    "# model training\n",
    "acc_no_nan,f1_no_nan = train_model(data_no_nans.reset_index(drop=True))\n",
    "print('Accuraccy with NANs removed : ',acc_no_nan, '\\nF1 score with NANs removed : ',f1_no_nan )\n",
    "\n",
    "\n",
    "# removing data failing red rules\n",
    "# removing same data_different_classes\n",
    "mis_classified_instances = data_no_nans.groupby('merged').filter(lambda x : (len(x['merged'])==x['out_class'].nunique())&(len(x['merged'])>1))#.sort_values(by = 'merged')\n",
    "data_no_nans_no_misclassified = data_no_nans.iloc[~data_no_nans.index.isin(mis_classified_instances.index),:].copy()\n",
    "\n",
    "\n",
    "classes_below_lower_lim = df_t2[df_t2.counts<min_vals_per_class].vals.tolist()\n",
    "data_no_nans_no_misclassified_no_red = data_no_nans_no_misclassified[~data_no_nans_no_misclassified.out_class.isin(classes_below_lower_lim)].copy()\n",
    "\n",
    "# model training\n",
    "acc_no_nan_no_red,f1_no_nan_no_red = train_model(data_no_nans_no_misclassified_no_red.reset_index(drop=True))\n",
    "print('Accuraccy with no NANs and no Red Rules violating Classes : ',acc_no_nan_no_red, '\\nF1 score with no NANs and no Red Rules violating Classes : ',f1_no_nan_no_red )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# removing data failing yellow rules\n",
    "classes_below_yellow_lim = df_t2[df_t2.counts<recommended_vals_per_class].vals.tolist()\n",
    "data_no_nans_no_misclassified_no_yelllow = data_no_nans_no_misclassified_no_red[~data_no_nans_no_misclassified_no_red.out_class.isin(classes_below_yellow_lim)].copy()\n",
    "\n",
    "\n",
    "# model training\n",
    "acc_no_nan_no_red_no_yellow,f1_no_nan_no_red_no_yellow = train_model(data_no_nans_no_misclassified_no_yelllow.reset_index(drop=True))\n",
    "print('Accuraccy with no NANs and no Red and Yellow Rules violating Classes : ',acc_no_nan_no_red_no_yellow, '\\nF1 score with no NANs and no Red and Yellow Rules violating Classes : ',f1_no_nan_no_red_no_yellow )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new ideas\n",
    "\n",
    "# sentences with all words gibbersih to be removed\n",
    "\n",
    "# same outclass in differenrt catagory\n",
    "\n",
    "# text length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data Quality \n",
    "# data left after removing data not following red rules\n",
    "# removing nans from merged data\n",
    "data_no_nans = data_all[data_all.merged != ','].copy()\n",
    "data_no_nans = data_no_nans[data_no_nans.out_class != ''].copy()\n",
    "# removing data failing red rules\n",
    "# removing same data_different_classes\n",
    "mis_classified_instances = data_no_nans.groupby('merged').filter(lambda x : (len(x['merged'])==x['out_class'].nunique())&(len(x['merged'])>1))#.sort_values(by = 'merged')\n",
    "data_no_nans_no_misclassified = data_no_nans.iloc[~data_no_nans.index.isin(mis_classified_instances.index),:].copy()\n",
    "classes_below_lower_lim = df_t2[df_t2.counts<min_vals_per_class].vals.tolist()\n",
    "data_no_nans_no_misclassified_no_red = data_no_nans_no_misclassified[~data_no_nans_no_misclassified.out_class.isin(classes_below_lower_lim)].copy()\n",
    "\n",
    "\n",
    "# removing data failing yellow rules\n",
    "classes_below_yellow_lim = df_t2[df_t2.counts<recommended_vals_per_class].vals.tolist()\n",
    "data_no_nans_no_misclassified_no_yelllow = data_no_nans_no_misclassified_no_red[~data_no_nans_no_misclassified_no_red.out_class.isin(classes_below_yellow_lim)].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results/Recommendations:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt = '\\n\\nResults/Recommendations:\\n'\n",
    "out_text = out_text + '\\n' + txt\n",
    "print(txt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after removing Red Rules defying data: 6378/7018, 90.8805927614705%\n",
      "Data after removing Yellow and Red Rules defying data: 5012/7018, 71.41635793673412%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "txt = 'Data after removing Red Rules defying data: ' + str(len(data_no_nans_no_misclassified_no_red))  + '/' + str(len(data_all)) + ', ' + str(len(data_no_nans_no_misclassified_no_red)/len(data_all)*100) + '%'\n",
    "out_text = out_text + '\\n' + txt\n",
    "print(txt)\n",
    "\n",
    "txt = 'Data after removing Yellow and Red Rules defying data: ' + str( len(data_no_nans_no_misclassified_no_yelllow)) + '/' + str(len(data_all))+ ', '+ str(len(data_no_nans_no_misclassified_no_yelllow)/len(data_all)*100)+'%'\n",
    "out_text = out_text + '\\n' + txt\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes after removing Red Rules defying data: 33/110, 30.0%\n",
      "Classes after removing Yellow and Red Rules defying data: 14/110, 12.727272727272727%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "txt = 'Classes after removing Red Rules defying data: ' + str(len(data_no_nans_no_misclassified_no_red.out_class.unique())) + '/' + str(len(data_all.out_class.unique()))+ ', ' + str(len(data_no_nans_no_misclassified_no_red.out_class.unique())/len(data_all.out_class.unique())*100)+ '%'\n",
    "out_text = out_text + '\\n' + txt\n",
    "print(txt)\n",
    "\n",
    "txt = 'Classes after removing Yellow and Red Rules defying data: ' + str(len(data_no_nans_no_misclassified_no_yelllow.out_class.unique())) +'/'+str(len(data_all.out_class.unique()))+', '+str(len(data_no_nans_no_misclassified_no_yelllow.out_class.unique())/len(data_all.out_class.unique())*100)+ '%'\n",
    "out_text = out_text + '\\n' + txt\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = (set(data_all.out_class.unique()) - set(data_no_nans_no_misclassified_no_red.out_class.unique()))\n",
    "txt = '\\n\\nClasses failing Red Rules are : \\n' + str(x)\n",
    "out_text = out_text + '\\n' + txt\n",
    "print(txt)\n",
    "\n",
    "\n",
    "\n",
    "x = ( set(data_no_nans_no_misclassified_no_red.out_class.unique()) - set(data_no_nans_no_misclassified_no_yelllow.out_class.unique()))\n",
    "txt = '\\n\\nClasses Failing Yellow and Red Rules are : \\n' + str(x)\n",
    "out_text = out_text + '\\n' + txt\n",
    "print(txt)\n",
    "\n",
    "\n",
    "x = (set(data_no_nans_no_misclassified_no_yelllow.out_class.unique()))\n",
    "txt = '\\n\\nClasses Passing Red and Yellow Rules are : \\n'+ str(x)\n",
    "out_text = out_text + '\\n' + txt\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
